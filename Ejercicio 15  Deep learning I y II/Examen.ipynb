{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prospective-america",
   "metadata": {},
   "source": [
    "Dado que el entrenamiento de redes neuronales es una tarea  muy costosa, **se recomienda ejecutar el notebooks en [Google Colab](https://colab.research.google.com)**, por supuesto también se puede ejecutar en local.\n",
    "\n",
    "Al entrar en [Google Colab](https://colab.research.google.com) bastará con hacer click en `upload` y subir este notebook. No olvide luego descargarlo en `File->Download .ipynb`\n",
    "\n",
    "**El examen deberá ser entregado con las celdas ejecutadas, si alguna celda no está ejecutadas no se contará.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-stewart",
   "metadata": {},
   "source": [
    "El examen se divide en dos partes, con la puntuación que se indica a continuación. La puntuación máxima será 10.\n",
    "\n",
    "- [Actividad 1: Redes Densas](#actividad_1): 5 pts\n",
    "    - Correcta normalización: máximo de 0.25 pts\n",
    "    - [Cuestión 1](#1.1): 1.5 pt\n",
    "    - [Cuestión 2](#1.2): 1.5 pt\n",
    "    - [Cuestión 3](#1.3): 0.5 pts\n",
    "    - [Cuestión 4](#1.4): 0.25 pts\n",
    "    - [Cuestión 5](#1.5): 0.25 pts\n",
    "    - [Cuestión 6](#1.6): 0.25 pts\n",
    "    - [Cuestión 7](#1.7): 0.25 pts\n",
    "    - [Cuestión 8](#1.8): 0.25 pts\n",
    "\n",
    "\n",
    "- [Actividad 2: Redes Convolucionales](#actividad_2): 5 pts\n",
    "    - [Cuestión 1](#2.1): 2.5 pt\n",
    "    - [Cuestión 2](#2.2): 1 pt\n",
    "    - [Cuestión 3](#2.3): 0.5 pts\n",
    "    - [Cuestión 4](#2.4): 0.5 pts\n",
    "    - [Cuestión 5](#2.5): 0.5 pts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prompt-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-correction",
   "metadata": {},
   "source": [
    "<a name='actividad_1'></a>\n",
    "# Actividad 1: Redes Densas\n",
    "\n",
    "Para esta primera actividad vamos a utilizar el [wine quality dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality). Con el que trataremos de predecir la calidad del vino.\n",
    "\n",
    "La calidad del vino puede tomar valores decimales (por ejemplo 7.25), independientemente de que en el dataset de entrenamiento sean números enteros. Por lo tanto, el problema es una `regresión`.\n",
    "\n",
    "**Puntuación**: \n",
    "\n",
    "Normalizar las features correctamente (x_train, x_test): 0.25 pts , se pueden normalizar con el [Normalization layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) de Keras. \n",
    "\n",
    "\n",
    "- Correcta normalización: máximo de 0.25 pts\n",
    "- [Cuestión 1](#1.1): 1 pt\n",
    "- [Cuestión 2](#1.2): 1 pt\n",
    "- [Cuestión 3](#1.3): 0.5 pts\n",
    "- [Cuestión 4](#1.4): 0.25 pts\n",
    "- [Cuestión 5](#1.5): 0.25 pts\n",
    "- [Cuestión 6](#1.6): 0.25 pts\n",
    "- [Cuestión 7](#1.7): 0.25 pts\n",
    "- [Cuestión 8](#1.8): 0.25 pts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e088b9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargar los datos con pandas\n",
    "df_red = pd.read_csv(\n",
    "    'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv',\n",
    "    sep=';'\n",
    ")\n",
    "df_white = pd.read_csv(\n",
    "    'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv',\n",
    "    sep=';'\n",
    ")\n",
    "df = pd.concat([df_red, df_white])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a547f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', \n",
    "    'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol'\n",
    "]\n",
    "\n",
    "\n",
    "# separar features y target\n",
    "y = df.pop('quality').values\n",
    "X = df.copy().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfb80ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train, y_train shapes: (4872, 11) (4872,)\n",
      "x_test, y_test shapes: (1625, 11) (1625,)\n",
      "Some qualities:  [6 7 8 5 6]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "print('x_train, y_train shapes:', x_train.shape, y_train.shape)\n",
    "print('x_test, y_test shapes:', x_test.shape, y_test.shape)\n",
    "print('Some qualities: ', y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Si quiere, puede normalizar las features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-planner",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "## Cuestión 1: Cree un modelo secuencial que contenga 4 capas ocultas(hidden layers), con más de 60 neuronas  por capa, sin regularización y obtenga los resultados.\n",
    "\n",
    "Puntuación: \n",
    "- Obtener el modelo correcto: 0.8 pts\n",
    "- Compilar el modelo: 0.1pts\n",
    "- Acertar con la función de pérdida: 0.1 pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "# Código aquí\n",
    "model.add(layers.Input(shape=(11), name=\"in_layer\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", name=\"layer1\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", name=\"layer2\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", name=\"layer3\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", name=\"layer4\"))\n",
    "model.add(layers.Dense(1, activation=\"linear\", name=\"out_layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "# Código aquí\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mean_squared_error\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modifique el código\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=200,\n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modifique el código\n",
    "results = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-delivery",
   "metadata": {},
   "source": [
    "<a name='1.2'></a>\n",
    "## Cuestión 2: Utilice el mismo modelo de la cuestión anterior pero añadiendo al menos dos técnicas distinas de regularización.\n",
    "\n",
    "Ejemplos de regularización: [Prevent_Overfitting.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Prevent_Overfitting.ipynb)\n",
    "\n",
    "Puntuación:\n",
    "\n",
    "- Obtener el modelo con la regularización: 0.8 pts\n",
    "- Obtener un `test loss` inferior al anterior: 0.2 pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "# Código aquí\n",
    "\n",
    "kernel_regularizer_l1_l2 = keras.regularizers.l1_l2(l1=1e-5, l2=5e-4)\n",
    "bias_regularizer_l2 = keras.regularizers.l2(3e-4)\n",
    "\n",
    "model.add(layers.Input(shape=(), name=\"in_layer\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", kernel_regularizer=kernel_regularizer_l1_l2, name=\"layer1\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", name=\"layer2\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", bias_regularizer=bias_regularizer_l2, name=\"layer3\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", name=\"layer4\"))\n",
    "model.add(layers.Dense(1, activation=\"linear\", name=\"out_layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "# Código aquí\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mean_squared_error\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modifique el código\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=200,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.2,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modifique el código\n",
    "results = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-vegetation",
   "metadata": {},
   "source": [
    "<a name='1.3'></a>\n",
    "## Cuestión 3: Utilice el mismo modelo de la cuestión anterior pero añadiendo un callback de early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "kernel_regularizer_l1_l2 = keras.regularizers.l1_l2(l1=1e-5, l2=5e-4)\n",
    "bias_regularizer_l2 = keras.regularizers.l2(3e-4)\n",
    "\n",
    "model.add(layers.Input(shape=(), name=\"in_layer\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", kernel_regularizer=kernel_regularizer_l1_l2, name=\"layer1\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", name=\"layer2\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", bias_regularizer=bias_regularizer_l2, name=\"layer3\"))\n",
    "model.add(layers.Dense(60, activation=\"sigmoid\", name=\"layer4\"))\n",
    "model.add(layers.Dense(1, activation=\"linear\", name=\"out_layer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "# Código aquí\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mean_squared_error\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "## definir el early stopping callback\n",
    "# Código aquí\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    min_delta=0,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=200,\n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop]) # Código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modifique el código\n",
    "results = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-lesbian",
   "metadata": {},
   "source": [
    "<a name='1.4'></a>\n",
    "## Cuestión 4: ¿Podría haberse usado otra función de activación de la neurona de salida? En caso afirmativo especifíquela."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-silicon",
   "metadata": {},
   "source": [
    "Podriamos haber usado la ReLU, ya que los valores de salida son iguales o mayores a 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-christianity",
   "metadata": {},
   "source": [
    "<a name='1.5'></a>\n",
    "## Cuestión 5:  ¿Qué es lo que una neurona calcula?\n",
    "\n",
    "**a)** Una función de activación seguida de una suma ponderada  de las entradas.\n",
    "\n",
    "**b)** Una suma ponderada  de las entradas seguida de una función de activación.\n",
    "\n",
    "**c)** Una función de pérdida, definida sobre el target.\n",
    "\n",
    "**d)** Ninguna  de las anteriores es correcta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-burden",
   "metadata": {},
   "source": [
    "*B*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-european",
   "metadata": {},
   "source": [
    "<a name='1.6'></a>\n",
    "## Cuestión 6:  ¿Cuál de estas funciones de activación no debería usarse en una capa oculta (hidden layer)?\n",
    "\n",
    "**a)** `sigmoid`\n",
    "\n",
    "**b)** `tanh`\n",
    "\n",
    "**c)** `relu`\n",
    "\n",
    "**d)** `linear`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-attack",
   "metadata": {},
   "source": [
    "*D*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-utilization",
   "metadata": {},
   "source": [
    "<a name='1.7'></a>\n",
    "## Cuestión 7:  ¿Cuál de estas técnicas es efectiva para combatir el overfitting en una red con varias capas ocultas? Ponga todas las que lo sean.\n",
    "\n",
    "**a)** Dropout\n",
    "\n",
    "**b)** Regularización L2.\n",
    "\n",
    "**c)** Aumentar el tamaño del test set.\n",
    "\n",
    "**d)** Aumentar el tamaño del validation set.\n",
    "\n",
    "**e)** Reducir el número de capas de la red.\n",
    "\n",
    "**f)** Data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-trainer",
   "metadata": {},
   "source": [
    "*a, b, e, f*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-deposit",
   "metadata": {},
   "source": [
    "<a name='1.8'></a>\n",
    "## Cuestión 8:  Supongamos que queremos entrenar una red para un problema de clasificación de imágenes con las siguientes clases: {'perro','gato','persona'}. ¿Cuántas neuronas y que función de activación debería tener la capa de salida? ¿Qué función de pérdida (loss function) debería usarse?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-roulette",
   "metadata": {},
   "source": [
    "Deberá tener 3 neuronas de salida, y como serán probabilidades \n",
    "la mejor función de activación será la **softmax** ya que\n",
    "su salida es estre 0 y 1  y la suma total será 1. \n",
    "\n",
    "La funcion de perdida adecuada será `categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-decade",
   "metadata": {},
   "source": [
    "<a name='actividad_2'></a>\n",
    "# Actividad 2: Redes Convolucionales\n",
    "\n",
    "Vamos a usar el dataset [cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html), que son 60000 imágenes de 32x32 a color  con 10 clases diferentes. Para realizar mejor la práctica puede consultar [Introduction_to_CNN.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CNN.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "**Puntuación**: \n",
    "\n",
    "- [Cuestión 1](#2.1): 2.5 pt\n",
    "- [Cuestión 2](#2.2): 1 pt\n",
    "- [Cuestión 3](#2.3): 0.5 pts\n",
    "- [Cuestión 4](#2.4): 0.5 pts\n",
    "- [Cuestión 5](#2.5): 0.5 pts\n",
    "\n",
    "Puede normalizar las imágenes al principio o usar la capa [Rescaling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling):\n",
    "\n",
    "```python\n",
    "tf.keras.layers.experimental.preprocessing.Rescaling(\n",
    "    scale, offset=0.0, name=None, **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train, y_train shapes:', x_train.shape, y_train.shape)\n",
    "print('x_test, y_test shapes:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-philosophy",
   "metadata": {},
   "source": [
    "<a name='2.1'></a>\n",
    "## Cuestión 1: Cree una red convolucional con la API funcional con al menos dos capas convolucionales y al menos dos capas de pooling. Debe obtener un `Test accuracy > 0.68`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32, 32, 3), name='input')\n",
    "# reescaling = \n",
    "rescaling = layers.Rescaling(1/255.0)(inputs)\n",
    "# Convolution + pooling layers\n",
    "conv_1 = layers.Conv2D(filters=8, kernel_size=3, padding=\"valid\", \n",
    "                            activation=\"relu\", name=\"conv\")(rescaling)\n",
    "pool_1 = layers.MaxPooling2D(pool_size=(2, 2), name='pool_1')(conv_1)\n",
    "\n",
    "conv_2 = layers.Conv2D(filters=4, kernel_size=3, padding='valid', activation='relu',\n",
    "                       name='conv_2')(pool_1)\n",
    "pool_2 = layers.MaxPooling2D(pool_size=(2, 2), name='pool_2')(conv_2)\n",
    "\n",
    "# Flattening\n",
    "flat = layers.Flatten(name='flatten')(pool_2)\n",
    "\n",
    "# Fully-connected\n",
    "dense = layers.Dense(64, activation='relu', name='dense')(flat)\n",
    "outputs = layers.Dense(10, activation='softmax', name='output')(dense)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=25, batch_size=64,\n",
    "                    validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1000)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-implement",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "## Cuestión 2: Cree el mismo  modelo de manera secuencial. No es necesario compilar ni entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq = tf.keras.models.Sequential()\n",
    "# Código aquí\n",
    "# Capa de entrada + normalización\n",
    "model.add(layers.Input(shape=(32, 32, 3), name='input'))\n",
    "model.add(layers.Rescaling(1/255.0))\n",
    "\n",
    "# Primera capa convolucional + pooling\n",
    "model.add(layers.Conv2D(filters=8, kernel_size=3, padding=\"valid\", activation=\"relu\", name=\"conv\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), name='pool_1'))\n",
    "\n",
    "# Segunda capa convolucional + pooling\n",
    "model.add(layers.Conv2D(filters=4, kernel_size=3, padding=\"valid\", activation=\"relu\", name=\"conv_2\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), name='pool_2'))\n",
    "\n",
    "# Aplanado y capas densas\n",
    "model.add(layers.Flatten(name='flatten'))\n",
    "model.add(layers.Dense(64, activation='relu', name='dense'))\n",
    "model.add(layers.Dense(10, activation='softmax', name='output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-consortium",
   "metadata": {},
   "source": [
    "<a name='2.3'></a>\n",
    "## Cuestión 3: Si tenenemos una  una imagen de entrada de 300 x 300 a color (RGB) y queremos usar una red densa. Si la primera capa oculta tiene 100 neuronas, ¿Cuántos parámetros tendrá esa capa (sin incluir el bias) ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-calcium",
   "metadata": {},
   "source": [
    "27 Millones de parametros que corresponderán a los pesos de cada neurona hacia cada entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-positive",
   "metadata": {},
   "source": [
    "<a name='2.4'></a>\n",
    "## Cuestión 4   Ponga  las verdaderas ventajas de las redes convolucionales respecto a las densas\n",
    "\n",
    "**a)** Reducen el número total de parámetros, reduciendo así el overfitting.\n",
    "\n",
    "**b)** Permiten utilizar una misma 'función'  en varias localizaciones de la imagen de entrada, en lugar de aprender una función diferente para cada pixel.\n",
    "\n",
    "**c)** Permiten el uso del transfer learning.\n",
    "\n",
    "**d)** Generalmente son menos profundas, lo que facilita su entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-nirvana",
   "metadata": {},
   "source": [
    "*a, b, c*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-toyota",
   "metadata": {},
   "source": [
    "<a name='2.5'></a>\n",
    "## Cuestión 5: Para el procesamiento de series temporales las redes convolucionales no son efectivas, habrá que usar redes recurrentes.\n",
    "\n",
    "- **Verdadero** \n",
    "- **Falso** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-seven",
   "metadata": {},
   "source": [
    "*Falso*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
